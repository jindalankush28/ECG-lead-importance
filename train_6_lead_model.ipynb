{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_881345/1797123261.py:13: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-04-23 14:51:37.117223: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-23 14:51:37.117250: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-23 14:51:37.118207: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-23 14:51:37.123182: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-23 14:51:39.546791: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "\n",
    "# Third-party libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Keras\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, Dense, Conv1D, Dropout, Activation, Flatten\n",
    "from keras.metrics import AUC\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import Sequence\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense, Flatten, LayerNormalization, MultiHeadAttention\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Local imports\n",
    "from models import Attia_et_al_CNN\n",
    "\n",
    "from utils import split_train_val_test\n",
    "\n",
    "# Environment variables\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load diagnostic_data.pickle\n",
    "data_df = pd.read_pickle('data/arrythmia_dataset.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = ['1AVB', 'AF', 'AFIB', 'APB', 'AQW', 'IDC',\n",
    "              'LVH', 'LVQRSAL', 'RBBB', 'SR', 'ST',\n",
    "              'STDD', 'STE', 'STTC', 'SVT', 'TWC',\n",
    "              'TWO']\n",
    "\n",
    "output_size = len(conditions)\n",
    "model = Attia_et_al_CNN(output_size=output_size).build(input_shape=(5000, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = 'limb' # Optimal, precordial, limb\n",
    "\n",
    "if MODEL_TYPE == 'optimal':\n",
    "    sel_leads = [0, 1, 3, 9, 10, 11]\n",
    "if MODEL_TYPE == 'limb':\n",
    "    sel_leads = [0, 1, 2, 3, 4, 5]\n",
    "if MODEL_TYPE == 'precordial':\n",
    "    sel_leads = [6, 7, 8, 9, 10, 11]\n",
    "if MODEL_TYPE == 'worst':\n",
    "    sel_leads = [2, 4, 5, 6, 7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "X, y = data_df['wf'].to_numpy(), data_df[conditions].to_numpy()\n",
    "y = y.astype(float)\n",
    "X = np.stack(X, axis=0)\n",
    "\n",
    "X = X[:, :, sel_leads]\n",
    "\n",
    "del data_df\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"y mean: {y.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_train_val_test(X, y, train_size=0.7, val_size=0.15)\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(X, y, batch_size=8):\n",
    "    row_nums = np.arange(X.shape[0])\n",
    "    np.random.shuffle(row_nums)\n",
    "    for i in range(0, len(row_nums), batch_size):\n",
    "        current_idxs = row_nums[i:i+batch_size]\n",
    "\n",
    "        yield X[current_idxs], y[current_idxs,:]\n",
    "\n",
    "output_signature = (\n",
    "    tf.TensorSpec(shape=(None, 5000, 6), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(None, output_size), dtype=tf.float32)\n",
    ")\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(generator=lambda: generator(X_train,y_train, 8), output_signature=output_signature)\n",
    "val_ds = tf.data.Dataset.from_generator(generator=lambda: generator(X_val,y_val, 8), output_signature=output_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate =1e-3\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    factor=0.5,  # Reduce learning rate by half when triggered\n",
    "    patience=3,  # Number of epochs with no improvement to trigger the callback\n",
    "    verbose=1,  # Print messages\n",
    "    min_lr=1e-8  # Minimum learning rate\n",
    ")\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6, mode='min', restore_best_weights=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate), metrics=['accuracy', AUC(name='auc')])\n",
    "# Training parameters\n",
    "EPOCHS = 50  # You can adjust based on your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    shuffle=True,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[reduce_lr, early_stopping],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "for i, condition in enumerate(conditions):\n",
    "    auc = roc_auc_score(y_test[:,i], y_pred[:,i])\n",
    "    print(f\"{condition}: {auc}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate AUROC\n",
    "pred = model.predict(X_test)\n",
    "auc = roc_auc_score(y_test, pred)\n",
    "print(f\"Test AUROC: {auc:.3f}\")\n",
    "\n",
    "# Train AUROC\n",
    "pred_train = model.predict(X_train, verbose=0)\n",
    "auc_train = roc_auc_score(y_train, pred_train)\n",
    "print(f\"Train AUROC: {auc_train:.3f}\")\n",
    "\n",
    "# Train AUROC\n",
    "pred_val = model.predict(X_val, verbose=0)\n",
    "auc_val = roc_auc_score(y_val, pred_val)\n",
    "print(f\"Val AUROC: {auc_train:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "model.save(f'models/12-lead/multi_output_cnn_{MODEL_TYPE}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = keras.models.load_model(f'models/12-lead/multi_output_cnn.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
